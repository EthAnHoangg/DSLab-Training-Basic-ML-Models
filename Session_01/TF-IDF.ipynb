{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_20newsgropups_data():\n",
    "    path = \"../datasets/20news-bydate/\"\n",
    "    test_dir, train_dir = sorted([path + dir_name\n",
    "            for dir_name in os.listdir(path)\n",
    "            if \"train\" in dir_name or \"test\" in dir_name])\n",
    "    \n",
    "    assert \"test\" in test_dir and \"train\" in train_dir\n",
    "    newsgroup_list = [news_group for news_group in os.listdir(train_dir)]\n",
    "    newsgroup_list.sort()\n",
    "    return newsgroup_list\n",
    "newsgroup_list = gather_20newsgropups_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../datasets/20news-bydate/stop_words.txt\") as f:\n",
    "    stop_words = (f.read().splitlines())\n",
    "    # print(stop_words)\n",
    "stemmer = PorterStemmer()\n",
    "def collect_data_from(parent_dir, newsgroup_list):\n",
    "    data = []\n",
    "    for group_id, newsgroup in enumerate (newsgroup_list):\n",
    "        label = group_id\n",
    "        dir_path = parent_dir + \"/\" + newsgroup + \"/\"\n",
    "        files = [(filename, dir_path + filename)\n",
    "                for filename in os.listdir(dir_path)\n",
    "                if os.path.isfile(dir_path + filename)]\n",
    "        files.sort()\n",
    "        for filename, filepath in files:\n",
    "            # print(filepath)\n",
    "            with open(filepath, errors = \"ignore\") as f:\n",
    "                text = f.read().lower()\n",
    "                words = [stemmer.stem(word)\n",
    "                        for word in re.split(\"\\W\", text)\n",
    "                        if word not in stop_words]\n",
    "\n",
    "                content = \" \".join(words)\n",
    "                assert len(content.splitlines()) == 1\n",
    "                data.append(str(label) + \"<fff>\" +\n",
    "                            filename + \"<fff>\" + content)\n",
    "    return data\n",
    "\n",
    "path = \"../datasets/20news-bydate/\"\n",
    "test_dir, train_dir = sorted([path + dir_name\n",
    "        for dir_name in os.listdir(path)\n",
    "        if \"train\" in dir_name or \"test\" in dir_name])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = collect_data_from(parent_dir= train_dir, newsgroup_list = newsgroup_list)\n",
    "test_data = collect_data_from(parent_dir= test_dir, newsgroup_list = newsgroup_list)\n",
    "full_data = train_data + test_data\n",
    "with open (\"../datasets/20news-bydate/20news-train-processed.txt\", \"w\") as f:\n",
    "    f.write('\\n'.join(train_data))\n",
    "with open (\"../datasets/20news-bydate/20news-test-processed.txt\", \"w\") as f:\n",
    "    f.write('\\n'.join(test_data))\n",
    "with open (\"../datasets/20news-bydate/20news-full-processed.txt\", \"w\") as f:\n",
    "    f.write('\\n'.join(full_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vocabulary(data_path):\n",
    "    def compute_idf(df, corpus_size):\n",
    "        assert df > 0\n",
    "        return np.log10(corpus_size * 1. / df)\n",
    "    with open (data_path) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    doc_count = defaultdict(int)\n",
    "\n",
    "    for line in lines:\n",
    "        features = line.split('<fff>')\n",
    "        text = features[-1]\n",
    "        words = list(set(text.split()))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
